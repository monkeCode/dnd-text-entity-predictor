base-model: DeepPavlov/bert-base-bg-cs-pl-ru-cased

max-tokens: 200
lower_texts: true
use_syntetic_data: true

train:
  epoches: 70
  lr: 0.00001
  early_stopping_patience: 5
  batch-size: 64
  num-workers: 5
  freeze: true
  dropout_rate: 0.1
  use_prev_label: false
  weights:
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
  - 1
